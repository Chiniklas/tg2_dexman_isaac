### ---- training teacher policy on single GPU ------###
## THIS THING WORKS.

cd ~/projects/DEXTRAH/dextrah_lab/rl_games

python -m torch.distributed.run --nnodes=1 --nproc_per_node=1 \
  train.py \
    --task=Dextrah-Kuka-Allegro \
    --seed -1 \
    --num_envs 4 \
    agent.params.config.minibatch_size=64 \
    agent.params.config.central_value_config.minibatch_size=64 \
    agent.params.config.learning_rate=0.0001 \
    agent.params.config.horizon_length=16 \
    agent.params.config.mini_epochs=4 \
    agent.params.config.multi_gpu=True \
    agent.wandb_activate=False \
    env.success_for_adr=0.4 \
    env.objects_dir=visdex_objects \
    env.adr_custom_cfg_dict.fabric_damping.gain="[10.0, 20.0]" \
    env.adr_custom_cfg_dict.reward_weights.finger_curl_reg="[-0.01, -0.01]" \
    env.adr_custom_cfg_dict.reward_weights.lift_weight="[5.0, 0.0]" \
    env.max_pose_angle=45.0 \
    env.use_cuda_graph=True

# this also WORKS
cd dextrah_lab/rl_games
python -m torch.distributed.run --nnodes=1 --nproc_per_node=1 \
  train.py \
    --headless \
    --task=Dextrah-Kuka-Allegro \
    --seed -1 \
    --num_envs 1024 \
    agent.params.config.minibatch_size=4096 \
    agent.params.config.central_value_config.minibatch_size=4096 \
    agent.params.config.learning_rate=0.0001 \
    agent.params.config.horizon_length=16 \
    agent.params.config.mini_epochs=4 \
    agent.params.config.multi_gpu=False \
    agent.wandb_activate=False \
    env.success_for_adr=0.4 \
    env.objects_dir=visdex_objects \
    env.adr_custom_cfg_dict.fabric_damping.gain="[10.0, 20.0]" \
    env.adr_custom_cfg_dict.reward_weights.finger_curl_reg="[-0.01, -0.01]" \
    env.adr_custom_cfg_dict.reward_weights.lift_weight="[5.0, 0.0]" \
    env.max_pose_angle=45.0 \
    env.use_cuda_graph=False


# FOR REPLAY TEACHER policy
cd dextrah_lab/rl_games
python play_test.py \
  --task Dextrah-Kuka-Allegro \
  --num_envs 4 \
  --objects_dir visdex_objects \
  --max_pose_angle 45 \
  --checkpoint /home/chizhang/projects/DEXTRAH/dextrah_lab/rl_games/logs/rl_games/dextrah_lstm/2025-12-04_00-32-49/nn/last_dextrah_lstm_ep_20000_rew_481.3178.pth

# for vision based distillation
cd /home/chizhang/projects/DEXTRAH/dextrah_lab/distillation
python -m torch.distributed.run --nnodes=1 --nproc_per_node=1 \
  run_distillation.py \
    --headless \
    --task=Dextrah-Kuka-Allegro \
    --num_envs 64 env.distillation=True \
    --enable_cameras env.simulate_stereo=True \
    --teacher /home/chizhang/projects/DEXTRAH/dextrah_lab/rl_games/logs/rl_games/dextrah_lstm/2025-12-04_00-32-49/nn/last_dextrah_lstm_ep_20000_rew_481.3178.pth \
    env.img_aug_type="rgb" \
    env.aux_coeff=10. \
    env.objects_dir="visdex_objects" \
    env.max_pose_angle=45.0 \
    env.adr_custom_cfg_dict.fabric_damping.gain="[10.0, 20.0]" \
    env.adr_custom_cfg_dict.reward_weights.finger_curl_reg="[-0.01, -0.01]" \
    env.adr_custom_cfg_dict.reward_weights.lift_weight="[5.0, 0.0]" \
    env.use_cuda_graph=True

# for evaluation of student policy
cd /home/chizhang/projects/DEXTRAH/dextrah_lab/distillation
python eval.py \
  --task=Dextrah-Kuka-Allegro \
  --num_envs 4 \
  --enable_cameras \
  --checkpoint /home/chizhang/projects/DEXTRAH/dextrah_lab/distillation/runs/Dextrah-Kuka-Allegro_10-23-19-15/nn/dextrah_student_100000_iters.pth \
  --num_episodes 10 \
  env.distillation=True \
  env.simulate_stereo=True \
  env.img_aug_type="rgb" \
  env.objects_dir="visdex_objects" \
  env.max_pose_angle=45.0 \
  env.adr_custom_cfg_dict.fabric_damping.gain="[10.0, 20.0]" \
  env.adr_custom_cfg_dict.reward_weights.finger_curl_reg="[-0.01, -0.01]" \
  env.adr_custom_cfg_dict.reward_weights.lift_weight="[5.0, 0.0]" \
  env.use_cuda_graph=True



# testing training kuka-inspirehand teacher policy
python -m torch.distributed.run --nnodes=1 --nproc_per_node=1 \
  train.py \
    --task=Dextrah-Kuka-Inspirehand \
    --seed -1 \
    --num_envs 4 \
    --headless\
    agent.params.config.minibatch_size=64 \
    agent.params.config.central_value_config.minibatch_size=64 \
    agent.params.config.learning_rate=0.0001 \
    agent.params.config.horizon_length=16 \
    agent.params.config.mini_epochs=4 \
    agent.params.config.multi_gpu=True \
    agent.wandb_activate=False \
    env.success_for_adr=0.4 \
    env.objects_dir=visdex_objects \
    env.adr_custom_cfg_dict.reward_weights.finger_curl_reg="[-0.01, -0.01]" \
    env.adr_custom_cfg_dict.reward_weights.lift_weight="[5.0, 0.0]" \
    env.use_cuda_graph=False
  
# test trained teacher policy
cd dextrah_lab/rl_games
python play_test.py \
  --task Dextrah-Kuka-Inspirehand \
  --num_envs 1 \
  --objects_dir visdex_objects \
  --max_pose_angle 45 \
  --checkpoint /home/chizhang/projects/DEXTRAH/dextrah_lab/rl_games/logs/rl_games/dextrah_lstm/2025-12-12_11-49-37/nn/last_dextrah_lstm_ep_20000_rew_-46.002758.pth

## TODO: training is difficult if I don't implement palm pose instructions
# the upstream allegro task uses fabric controller to ensure the palm is always facing the object 
