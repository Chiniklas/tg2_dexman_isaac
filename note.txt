### ---- training teacher policy on single GPU ------###
## THIS THING WORKS.

cd ~/projects/DEXTRAH/dextrah_lab/rl_games

python -m torch.distributed.run --nnodes=1 --nproc_per_node=1 \
  train.py \
    --task=Dextrah-Kuka-Allegro \
    --seed -1 \
    --num_envs 4 \
    agent.params.config.minibatch_size=64 \
    agent.params.config.central_value_config.minibatch_size=64 \
    agent.params.config.learning_rate=0.0001 \
    agent.params.config.horizon_length=16 \
    agent.params.config.mini_epochs=4 \
    agent.params.config.multi_gpu=True \
    agent.wandb_activate=False \
    env.success_for_adr=0.4 \
    env.objects_dir=visdex_objects \
    env.adr_custom_cfg_dict.fabric_damping.gain="[10.0, 20.0]" \
    env.adr_custom_cfg_dict.reward_weights.finger_curl_reg="[-0.01, -0.01]" \
    env.adr_custom_cfg_dict.reward_weights.lift_weight="[5.0, 0.0]" \
    env.max_pose_angle=45.0 \
    env.use_cuda_graph=True

# this also WORKS
cd dextrah_lab/rl_games
python -m torch.distributed.run --nnodes=1 --nproc_per_node=1 \
  train.py \
    --headless \
    --task=Dextrah-Kuka-Allegro \
    --seed -1 \
    --num_envs 1024 \
    agent.params.config.minibatch_size=4096 \
    agent.params.config.central_value_config.minibatch_size=4096 \
    agent.params.config.learning_rate=0.0001 \
    agent.params.config.horizon_length=16 \
    agent.params.config.mini_epochs=4 \
    agent.params.config.multi_gpu=False \
    agent.wandb_activate=False \
    env.success_for_adr=0.4 \
    env.objects_dir=visdex_objects \
    env.adr_custom_cfg_dict.fabric_damping.gain="[10.0, 20.0]" \
    env.adr_custom_cfg_dict.reward_weights.finger_curl_reg="[-0.01, -0.01]" \
    env.adr_custom_cfg_dict.reward_weights.lift_weight="[5.0, 0.0]" \
    env.max_pose_angle=45.0 \
    env.use_cuda_graph=False


# FOR REPLAY TEACHER policy
cd dextrah_lab/rl_games
python play_test.py \
  --task Dextrah-Kuka-Allegro \
  --num_envs 4 \
  --objects_dir visdex_objects \
  --max_pose_angle 45 \
  --checkpoint /home/chizhang/projects/DEXTRAH/dextrah_lab/rl_games/logs/rl_games/dextrah_lstm/2025-12-04_00-32-49/nn/last_dextrah_lstm_ep_20000_rew_481.3178.pth

# for vision based distillation
cd /home/chizhang/projects/DEXTRAH/dextrah_lab/distillation
python -m torch.distributed.run --nnodes=1 --nproc_per_node=1 \
  run_distillation.py \
    --headless \
    --task=Dextrah-Kuka-Allegro \
    --num_envs 64 env.distillation=True \
    --enable_cameras env.simulate_stereo=True \
    --teacher /home/chizhang/projects/DEXTRAH/dextrah_lab/rl_games/logs/rl_games/dextrah_lstm/2025-12-04_00-32-49/nn/last_dextrah_lstm_ep_20000_rew_481.3178.pth \
    env.img_aug_type="rgb" \
    env.aux_coeff=10. \
    env.objects_dir="visdex_objects" \
    env.max_pose_angle=45.0 \
    env.adr_custom_cfg_dict.fabric_damping.gain="[10.0, 20.0]" \
    env.adr_custom_cfg_dict.reward_weights.finger_curl_reg="[-0.01, -0.01]" \
    env.adr_custom_cfg_dict.reward_weights.lift_weight="[5.0, 0.0]" \
    env.use_cuda_graph=True

# for evaluation of student policy
cd /home/chizhang/projects/DEXTRAH/dextrah_lab/distillation
python eval.py \
  --task=Dextrah-Kuka-Allegro \
  --num_envs 4 \
  --enable_cameras \
  --checkpoint /home/chizhang/projects/DEXTRAH/dextrah_lab/distillation/runs/Dextrah-Kuka-Allegro_10-23-19-15/nn/dextrah_student_100000_iters.pth \
  --num_episodes 10 \
  env.distillation=True \
  env.simulate_stereo=True \
  env.img_aug_type="rgb" \
  env.objects_dir="visdex_objects" \
  env.max_pose_angle=45.0 \
  env.adr_custom_cfg_dict.fabric_damping.gain="[10.0, 20.0]" \
  env.adr_custom_cfg_dict.reward_weights.finger_curl_reg="[-0.01, -0.01]" \
  env.adr_custom_cfg_dict.reward_weights.lift_weight="[5.0, 0.0]" \
  env.use_cuda_graph=True



# testing training kuka-inspirehand teacher policy
(HYDRA_FULL_ERROR=1)
python -m torch.distributed.run --nnodes=1 --nproc_per_node=1 \
  train.py \
    --task=Dextrah-Kuka-Inspirehand \
    --seed 42 \
    --num_envs 4 \
    --headless\
    agent.params.config.minibatch_size=64 \
    agent.params.config.central_value_config.minibatch_size=64 \
    agent.params.config.learning_rate=0.0001 \
    agent.params.config.horizon_length=16 \
    agent.params.config.mini_epochs=4 \
    agent.params.config.multi_gpu=False \
    agent.wandb_activate=False \
    env.success_for_adr=0.4 \
    env.objects_dir=visdex_objects \
    env.use_cuda_graph=False

# training with one object only
python -m torch.distributed.run --nnodes=1 --nproc_per_node=1 \
  train.py \
    --task=Dextrah-Kuka-Inspirehand \
    --seed 42 \
    --num_envs 256 \
    --headless\
    --sigma 1.5 \
    agent.params.config.minibatch_size=64 \
    agent.params.config.central_value_config.minibatch_size=64 \
    agent.params.config.learning_rate=0.0001 \
    agent.params.config.horizon_length=16 \
    agent.params.config.mini_epochs=4 \
    agent.params.config.multi_gpu=False \
    agent.wandb_activate=False \
    env.success_for_adr=0.4 \
    env.objects_dir=test_object \
    env.use_cuda_graph=False
  
# test trained teacher policy
cd dextrah_lab/rl_games
python play_test.py \
  --task Dextrah-Kuka-Inspirehand \
  --num_envs 8 \
  --objects_dir visdex_objects \
  --max_pose_angle 45 \
  --checkpoint /home/chizhang/projects/DEXTRAH/dextrah_lab/rl_games/logs/rl_games/dextrah_lstm/2025-12-12_11-49-37/nn/last_dextrah_lstm_ep_20000_rew_-46.002758.pth

# for tg2 tasks 
python train.py \
  --task=dextrah_tg2_inspirehand \
  --seed 42 \
  --num_envs 64 \
  --headless \
  agent.params.config.minibatch_size=128 \
  agent.params.config.central_value_config.minibatch_size=128 \
  agent.params.config.learning_rate=0.0001 \
  agent.params.config.horizon_length=16 \
  agent.params.config.mini_epochs=4 \
  agent.params.config.multi_gpu=False \
  agent.wandb_activate=False \
  env.success_for_adr=0.4 \
  env.objects_dir=test_object \
  env.use_cuda_graph=False


maybe num_envs 128, minibatch_size = 512

python train.py \
    --task=dextrah_tg2_inspirehand \
    --seed 42 \
    --num_envs 16 \
    --headless \
    agent.params.config.minibatch_size=64 \
    agent.params.config.central_value_config.minibatch_size=64 \
    agent.params.config.learning_rate=0.0001 \
    agent.params.config.horizon_length=16 \
    agent.params.config.mini_epochs=4 \
    agent.params.config.multi_gpu=False \
    agent.wandb_activate=False \
    env.success_for_adr=0.4 \
    env.objects_dir=test_object \
    env.use_cuda_graph=False

python play_test.py \
  --task dextrah_tg2_inspirehand \
  --num_envs 8 \
  --objects_dir test_object_0 \
  --max_pose_angle 90 \
  --checkpoint /home/chizhang/projects/dextrah/tg2_dexman_isaac/dextrah_lab/rl_games/logs/rl_games/dextrah_lstm/2026-01-21_08-57-56/nn/dextrah_lstm.pth

# batch training
MULTI_OBJECTS_DIR=/home/chizhang/projects/dextrah/tg2_dexman_isaac/dextrah_lab/assets/multi_objects/USD \
NUM_ENVS=128 \
MINIBATCH_SIZE=64 \
CV_MINIBATCH_SIZE=64 \
LEARNING_RATE=0.0001 \
HORIZON_LENGTH=16 \
MINI_EPOCHS=4 \
MULTI_GPU=False \
WANDB_ACTIVATE=False \
SUCCESS_FOR_ADR=0.4 \
USE_CUDA_GRAPH=False \
./train_multi_objects.sh

# initial trial on distillation (stereo transformer style)
cd /home/chizhang/projects/dextrah/tg2_dexman_isaac/dextrah_lab/distillation_new
python -m torch.distributed.run --nproc_per_node=1 \
  run_distillation.py \
    --headless \
    --task=dextrah_tg2_inspirehand \
    --num_envs 8 \
    --enable_cameras \
    --teacher dextrah_lstm.pth \
    env.distillation=True \
    env.simulate_stereo=True \
    env.objects_dir=test_object_0 \
    env.enable_adr=False \
    env.disable_arm_randomization=True

# replay student policy
cd /home/chizhang/projects/dextrah/tg2_dexman_isaac/dextrah_lab/distillation_new
python eval.py \
  --task=dextrah_tg2_inspirehand \
  --num_envs 8 \
  --enable_cameras \
  --checkpoint /home/chizhang/projects/dextrah/tg2_dexman_isaac/dextrah_lab/distillation_new/runs/<your_run>/nn/<student_ckpt>.pth \
  --num_episodes 10 \
  env.distillation=True \
  env.simulate_stereo=True \
  env.objects_dir=test_object_0
# optional recording
  --record_data --max_records_per_file 100 --create_video
